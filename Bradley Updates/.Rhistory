#top_new <- top %>%
#  left_join(data, by = c("X1" = "X1", "X2" = "X2"))
#sampling <- rbind(top_new,sampling)
f_min <- min(sampling$Value)
f_min
fitted_model <- DiceKriging::km(formula = ~1,
design = cbind(sampling$X1,sampling$X2),
response = sampling$Value,
covtype = "exp",
control = list(trace=FALSE))
## Function that input a location from (0,1) x (0,1)
## And output the y hat and s
expected_improvement <- function(x) {
y <- predict(fitted_model, matrix(x,nrow = 1), "UK")$mean
s <- predict(fitted_model, matrix(x,nrow = 1), "UK")$sd
return(c(y, s))
}
expected_improvement(c(0.1,0.1))
# negative expected improvement function (we try to minimize)
Neg_EI = function(x, f_min = 0) {
param = expected_improvement(x)
y = param[1]
s = param[2]
z = (f_min-y)/s
-(f_min-y)*pnorm(z)-s*dnorm(z)
}
grid_points = 1e2
grid = seq(0, 1, length.out=grid_points)
z = matrix(numeric(grid_points^2), nrow = grid_points)
for (i in 1:grid_points) {
for (j in 1:grid_points) {
z[i,j] = Neg_EI(c(grid[i],grid[j]))
}
}
contour(x=grid,y=grid,z)
h = Neg_EI # comment to test other h
dim = 2
# number of iterations
M = 1e2
# vector of T_1, T_2, ..., T_M closer to 0
big_T = 1/(1:M)
# number of iterations for each Metropolis-Hastings (sampling) alogrithm
N = rep(1e2,M)
# starting point
x0 = rep(0,dim)
# best value and point
best = c(h(x0),x0)
current = x0
for (k in 1:M) {
target = function(x, f_min=0) {
exp(-h(x, f_min) / big_T[k])
}
pi_current = target(current)
for (i in N[k]) {
# proposed point and target function value
proposed = rnorm(dim,current,0.5)%%1
pi_proposed = target(proposed)
u = runif(1)
# accept/reject proposed point
if (pi_current < Inf & (pi_current == 0 | u <= pi_proposed / pi_current)) {
current = proposed
pi_current = pi_proposed
}
# update the best point and value if value is better
h_current = h(current)
if (h_current < best[1]) {
best = c(h_current, current)
}
}
}
best
#optimize(h,interval=c(-10,10)) # if h is 1-dim
DiceKriging::branin(top)
top
top <- data.frame(X1 = best[2],
X2 = best[3])
top$Value <- DiceKriging::branin(top)
top$Value
#top_new <- top %>%
#  left_join(data, by = c("X1" = "X1", "X2" = "X2"))
sampling <- rbind(top_new,sampling)
f_min <- min(sampling$Value)
f_min
## Estimate parameters
fitted_model <- DiceKriging::km(formula = ~1,
design = cbind(sampling$X1,sampling$X2),
response = sampling$Value,
covtype = "exp",
control = list(trace=FALSE))
## Estimate parameters
fitted_model <- DiceKriging::km(formula = ~1,
design = cbind(sampling$X1,sampling$X2),
response = sampling$Value,
covtype = "matern5_2",
control = list(trace=FALSE))
?DiceKriging::km
## Estimate parameters
fitted_model <- DiceKriging::km(formula = ~1,
design = cbind(sampling$X1,sampling$X2),
response = sampling$Value,
covtype = "matern5_2",
control = list(trace=FALSE))
## Estimate parameters
fitted_model <- DiceKriging::km(formula = ~1,
design = cbind(sampling$X1,sampling$X2),
response = sampling$Value,
covtype = "matern5_2",
control = list(trace=FALSE))
data <- data %>%
mutate(X1 = round(X1, digits = 2),
X2 = round(X2, digits = 2))
data$Value <- apply(data[,1:2], 1, DiceKriging::branin)
sampling <- sampling %>%
mutate(X1 = round(X1, digits = 2),
X2 = round(X2, digits = 2))
sampling <- read_xlsx("initial_sampling_data.xlsx", col_names = FALSE)
data <- read_xlsx("data.xlsx", col_names = FALSE)
sampling <- read_xlsx("initial_sampling_data.xlsx", col_names = FALSE)
colnames(data) <- c("X1", "X2", "Value")
colnames(sampling) <- c("X1", "X2", "Value")
data <- data %>%
mutate(X1 = round(X1, digits = 2),
X2 = round(X2, digits = 2))
data$Value <- apply(data[,1:2], 1, DiceKriging::branin)
sampling <- sampling %>%
mutate(X1 = round(X1, digits = 2),
X2 = round(X2, digits = 2))
sampling <- sampling %>%
filter(!is.na(X1)) %>%
select(X1, X2) %>%
left_join(data, by = c("X1" = "X1", "X2" = "X2")) %>%
filter(!is.na(Value))
top <- data.frame(X1 = best[2],
X2 = best[3])
top$Value <- DiceKriging::branin(top)
#top_new <- top %>%
#  left_join(data, by = c("X1" = "X1", "X2" = "X2"))
sampling <- rbind(top_new,sampling)
f_min <- min(sampling$Value)
best
sampling <- read_xlsx("initial_sampling_data.xlsx", col_names = FALSE)
sampling <- sampling %>%
mutate(X1 = round(X1, digits = 2),
X2 = round(X2, digits = 2))
## Read
data <- read_xlsx("data.xlsx", col_names = FALSE)
sampling <- read_xlsx("initial_sampling_data.xlsx", col_names = FALSE)
colnames(data) <- c("X1", "X2", "Value")
colnames(sampling) <- c("X1", "X2", "Value")
data <- data %>%
mutate(X1 = round(X1, digits = 2),
X2 = round(X2, digits = 2))
data$Value <- apply(data[,1:2], 1, DiceKriging::branin)
sampling <- sampling %>%
mutate(X1 = round(X1, digits = 2),
X2 = round(X2, digits = 2))
sampling <- sampling %>%
filter(!is.na(X1)) %>%
select(X1, X2) %>%
left_join(data, by = c("X1" = "X1", "X2" = "X2")) %>%
filter(!is.na(Value))
top <- data.frame(X1 = best[2],
X2 = best[3])
top$Value <- DiceKriging::branin(top)
#top_new <- top %>%
#  left_join(data, by = c("X1" = "X1", "X2" = "X2"))
sampling <- rbind(top,sampling)
f_min <- min(sampling$Value)
## Estimate parameters
fitted_model <- DiceKriging::km(formula = ~1,
design = cbind(sampling$X1,sampling$X2),
response = sampling$Value,
covtype = "matern5_2",
control = list(trace=FALSE))
#set.seed(0)
# negative expected improvement function (we try to minimize)
Neg_EI = function(x) {
param = expected_improvement(x)
y = param[1]
s = param[2]
z = (f_min-y)/s
-(f_min-y)*pnorm(z)-s*dnorm(z)
}
grid_points = 1e2
grid = seq(0, 1, length.out=grid_points)
z = matrix(numeric(grid_points^2), nrow = grid_points)
for (i in 1:grid_points) {
for (j in 1:grid_points) {
z[i,j] = Neg_EI(c(grid[i],grid[j]))
}
}
contour(x=grid,y=grid,z)
h = Neg_EI # comment to test other h
dim = 2
# number of iterations
M = 1e2
# vector of T_1, T_2, ..., T_M closer to 0
big_T = 1/(1:M)
# number of iterations for each Metropolis-Hastings (sampling) alogrithm
N = rep(1e2,M)
# starting point
x0 = rep(0,dim)
# best value and point
best = c(h(x0),x0)
current = x0
for (k in 1:M) {
target = function(x) {
exp(-h(x) / big_T[k])
}
pi_current = target(current)
for (i in N[k]) {
# proposed point and target function value
proposed = rnorm(dim,current,0.5)%%1
pi_proposed = target(proposed)
u = runif(1)
# accept/reject proposed point
if (pi_current < Inf & (pi_current == 0 | u <= pi_proposed / pi_current)) {
current = proposed
pi_current = pi_proposed
}
# update the best point and value if value is better
h_current = h(current)
if (h_current < best[1]) {
best = c(h_current, current)
}
}
}
best
#optimize(h,interval=c(-10,10)) # if h is 1-dim
View(data)
pnorm(0.18-0.18/150*2,0.18,0.18/150)
sqrt(5)
reticulate::repl_python()
quit
knitr::opts_chunk$set(echo = TRUE,
message = FALSE,
warning = FALSE,
fig.align = "center",
fig.height = 8,
fig.width = 6)
reticulate::repl_python()
tau_x1 = integrated_time(x[1,])
tau_x1
View(r)
import numpy as np
import matplotlib.pyplot as plt
from emcee.autocorr import integrated_time
tau_x1 = integrated_time(x[1,])
tau_x1
tau_x1
print(tau_x1)
value(tau_x1)
quit
tau_x1 = IAT(x[1,])
install.packages("LaplacesDemon")
library(LaplacesDemon)
tau_x1 = IAT(x[1,])
knitr::opts_chunk$set(echo = TRUE,
message = FALSE,
warning = FALSE,
fig.align = "center",
fig.height = 8,
fig.width = 6)
mu = c(1,2,3)
Sigma = matrix(c(1,0,0.2,
0,9,2.7,
0.2,2.7,1),nrow=3,ncol=3,byrow=TRUE)
sigma = sapply(1:3,function(x) {sqrt(Sigma[x,x])})
rho12 = Sigma[1,2]/sigma[1]/sigma[2]
rho13 = Sigma[1,3]/sigma[1]/sigma[3]
rho23 = Sigma[2,3]/sigma[2]/sigma[3]
rho = c(rho23,rho13,rho12) # so that rho[i] = rho_{-i}
Rho = matrix(c(0, rho12, rho13,
rho12, 0, rho23,
rho13, rho23, 0),nrow=3,ncol=3,byrow=TRUE)
M = 1e5
set.seed(0)
x = matrix(numeric(0.5*M*3),nrow=3)
current = rep(0,3)
iter = rep(1,3)
# random scan
for (i in 1:M) {
coord = sample(3,1)
mu_bar = mu[coord] + sigma[coord]/(1-rho[coord]^2) * sum((Rho[-coord,coord]-rev(Rho[-coord,coord])*rho[coord])/sigma[-coord]*(current[-coord]-mu[-coord]))
sigma_bar = sigma[coord]^2/(1-rho[coord]^2)*(sum(rho[-coord]^2)-2*prod(rho))
current[coord] = rnorm(1,mu_bar,sqrt(sigma_bar))
x[coord,iter[coord]] = current[coord]
iter[coord] = iter[coord]+1
}
y = matrix(numeric(0.5*M*3),nrow=3)
current = rep(0,3)
iter = rep(1,3)
coord0 = 0
# systematic scan
for (i in 1:M) {
coord = coord0 + 1
mu_bar = mu[coord] + sigma[coord]/(1-rho[coord]^2) * sum((Rho[-coord,coord]-rev(Rho[-coord,coord])*rho[coord])/sigma[-coord]*(current[-coord]-mu[-coord]))
sigma_bar = sigma[coord]^2/(1-rho[coord]^2)*(sum(rho[-coord]^2)-2*prod(rho))
current[coord] = rnorm(1,mu_bar,sqrt(sigma_bar))
y[coord,iter[coord]] = current[coord]
iter[coord] = iter[coord]+1
coord0 = coord%%3
}
x = x[,1:(0.326*M)]
y = y[,1:(0.326*M)]
par(mfrow=c(3,2))
plot(x[1,],type="l",ylab = "x1 samples", main = "Random scan")
plot(y[1,],type="l",ylab = "x1 samples", main = "Systematic scan")
plot(x[2,],type="l",ylab = "x2 samples", main = "Random scan")
plot(y[2,],type="l",ylab = "x2 samples", main = "Systematic scan")
plot(x[3,],type="l",ylab = "x3 samples", main = "Random scan")
plot(y[3,],type="l",ylab = "x3 samples", main = "Systematic scan")
plot(x[1,],x[2,],pch=".",xlab="x1 samples", ylab = "x2 samples", main = "Random scan")
plot(y[1,],y[2,],pch=".",xlab="x1 samples", ylab = "x2 samples", main = "Systematic scan")
plot(x[1,],x[3,],pch=".",xlab="x1 samples", ylab = "x3 samples", main = "Random scan")
plot(y[1,],y[3,],pch=".",xlab="x1 samples", ylab = "x3 samples", main = "Systematic scan")
plot(x[2,],x[3,],pch=".",xlab="x2 samples", ylab = "x3 samples", main = "Random scan")
plot(x[2,],x[3,],pch=".",xlab="x2 samples", ylab = "x3 samples", main = "Systematic scan")
x = x[,-(1:2500)]
y = y[,-(1:2500)]
ks.test(x[1,],"pnorm",mean=mean(x[1,]),sd=sd(y[1,]))
ks.test(x[2,],"pnorm",mean=mean(x[2,]),sd=sd(y[2,]))
ks.test(x[3,],"pnorm",mean=mean(x[3,]),sd=sd(y[3,]))
ks.test(y[1,],"pnorm",mean=mean(y[1,]),sd=sd(y[1,]))
ks.test(y[2,],"pnorm",mean=mean(y[2,]),sd=sd(y[2,]))
ks.test(y[3,],"pnorm",mean=mean(y[3,]),sd=sd(y[3,]))
m = length(x[1,])
early = 1:floor(m*0.1)
late = floor(m*0.5):m
n1 = length(early)
n2 = length(late)
x11 = x[1,early]
x12 = x[1,late]
numerator = mean(x11)-mean(x12)
denominator = sqrt(var(x11)/n1+var(x12)/n2)
numerator/denominator
x21 = x[2,early]
x22 = x[2,late]
numerator = mean(x21)-mean(x22)
denominator = sqrt(var(x21)/n1+var(x22)/n2)
numerator/denominator
x31 = x[3,early]
x32 = x[3,late]
numerator = mean(x31)-mean(x32)
denominator = sqrt(var(x31)/n1+var(x32)/n2)
numerator/denominator
y11 = y[1,early]
y12 = y[1,late]
numerator = mean(y11)-mean(y12)
denominator = sqrt(var(y11)/n1+var(y12)/n2)
numerator/denominator
y21 = y[2,early]
y22 = y[2,late]
numerator = mean(y21)-mean(y22)
denominator = sqrt(var(y21)/n1+var(y22)/n2)
numerator/denominator
y31 = y[3,early]
y32 = y[3,late]
numerator = mean(y31)-mean(y32)
denominator = sqrt(var(y31)/n1+var(y32)/n2)
numerator/denominator
tau_x1 = IAT(x[1,])
tau_x2 = IAT(x[2,])
tau_x3 = IAT(x[3,])
n = length(x[1,])
library(LaplacesDemon)
n = length(x[1,])
tau_x1 = IAT(x[1,])
tau_x2 = IAT(x[2,])
tau_x3 = IAT(x[3,])
tau_y1 = IAT(y[1,])
tau_y2 = IAT(y[2,])
tau_y3 = IAT(y[3,])
n/(2*tau_x1)
n/(2*tau_x2)
n/(2*tau_x3)
n/(2*tau_y1)
n/(2*tau_y2)
n/(2*tau_y3)
length(x[1,])
knitr::opts_chunk$set(echo = TRUE,
message = FALSE,
warning = FALSE,
fig.align = "center",
fig.height = 8,
fig.width = 6)
mu = c(1,2,3)
Sigma = matrix(c(1,0,0.2,
0,9,2.7,
0.2,2.7,1),nrow=3,ncol=3,byrow=TRUE)
sigma = sapply(1:3,function(x) {sqrt(Sigma[x,x])})
rho12 = Sigma[1,2]/sigma[1]/sigma[2]
rho13 = Sigma[1,3]/sigma[1]/sigma[3]
rho23 = Sigma[2,3]/sigma[2]/sigma[3]
rho = c(rho23,rho13,rho12) # so that rho[i] = rho_{-i}
Rho = matrix(c(0, rho12, rho13,
rho12, 0, rho23,
rho13, rho23, 0),nrow=3,ncol=3,byrow=TRUE)
M = 1e5
set.seed(0)
x = matrix(numeric(0.5*M*3),nrow=3)
current = rep(0,3)
iter = rep(1,3)
# random scan
for (i in 1:M) {
coord = sample(3,1)
mu_bar = mu[coord] + sigma[coord]/(1-rho[coord]^2) * sum((Rho[-coord,coord]-rev(Rho[-coord,coord])*rho[coord])/sigma[-coord]*(current[-coord]-mu[-coord]))
sigma_bar = sigma[coord]^2/(1-rho[coord]^2)*(sum(rho[-coord]^2)-2*prod(rho))
current[coord] = rnorm(1,mu_bar,sqrt(sigma_bar))
x[coord,iter[coord]] = current[coord]
iter[coord] = iter[coord]+1
}
y = matrix(numeric(0.5*M*3),nrow=3)
current = rep(0,3)
iter = rep(1,3)
coord0 = 0
# systematic scan
for (i in 1:M) {
coord = coord0 + 1
mu_bar = mu[coord] + sigma[coord]/(1-rho[coord]^2) * sum((Rho[-coord,coord]-rev(Rho[-coord,coord])*rho[coord])/sigma[-coord]*(current[-coord]-mu[-coord]))
sigma_bar = sigma[coord]^2/(1-rho[coord]^2)*(sum(rho[-coord]^2)-2*prod(rho))
current[coord] = rnorm(1,mu_bar,sqrt(sigma_bar))
y[coord,iter[coord]] = current[coord]
iter[coord] = iter[coord]+1
coord0 = coord%%3
}
6202/1e5
1e5/6202
1/(2*tau_x1)
1e5/6202*2
1e5/6202/2
library(LaplacesDemon)
n = length(x[1,])
tau_x1 = IAT(x[1,])
tau_x2 = IAT(x[2,])
tau_x3 = IAT(x[3,])
tau_y1 = IAT(y[1,])
tau_y2 = IAT(y[2,])
tau_y3 = IAT(y[3,])
2*tau_x1
2*tau_x2
2*tau_x3
2*tau_y1
2*tau_y2
2*tau_y3
library(LaplacesDemon)
n = length(x[1,])
tau_x1 = IAT(x[1,])
tau_x2 = IAT(x[2,])
tau_x3 = IAT(x[3,])
tau_y1 = IAT(y[1,])
tau_y2 = IAT(y[2,])
tau_y3 = IAT(y[3,])
n/(2*tau_x1)
2*tau_x1
n/(2*tau_x2)
2*tau_x2
n/(2*tau_x3)
2*tau_x3
n/(2*tau_y1)
2*tau_y1
n/(2*tau_y2)
2*tau_y2
n/(2*tau_y3)
2*tau_y3
pnorm(0.18-2*sqrt(0.18*(1-0.18)/150),0.18,sqrt(0.18*(1-0.18)/150))
pnorm(-2,0,1)
pnorm(1,0,1)
pnorm(-2,0,1)
pnorm(2,0,1)
pnorm(0,0,1)
qnorm(0.05)
qnorm(0.025)
pnorm(-1.96,0,1)
pnorm(0.18-1.96*sqrt(0.18*(1-0.18)/150),0.18,sqrt(0.18*(1-0.18)/150))
dbinom(14,n=15,p=0.7)
dbinom(14,size=15,p=0.7)
dbinom(15,size=15,p=0.7)
1- pbinom(13,size=15,p=0.7)
source("C:/Users/bradl/Desktop/STATS 202C/Bradley Updates/Stats202c_branin (most recent).R")
source("C:/Users/bradl/Desktop/STATS 202C/Bradley Updates/Stats202c_profit (most recent).R")
source("C:/Users/bradl/Desktop/STATS 202C/Bradley Updates/Stats202c_profit (most recent).R")
setwd("C:/Users/bradl/Desktop/STATS 202C/Bradley Updates")
source("C:/Users/bradl/Desktop/STATS 202C/Bradley Updates/Stats202c_profit (most recent).R")
source("C:/Users/bradl/Desktop/STATS 202C/Bradley Updates/Stats202c_branin (most recent).R")
x <- lhs::maximinLHS(20,2)
x
x <- lhs::maximinLHS(40,1)
x
data <- read_xlsx("data.xlsx", col_names = FALSE)
colnames(data) <- c("X1", "X2", "Value")
### Set Up 1: Brannin Function
data$Value <- apply(data[,1:2], 1, DiceKriging::branin)
x <- lhs::maximinLHS(20,2)
sampling <- data.frame(X1 = x[,1], X2 = x[,2], Value = 0)
colnames(sampling) <- c("X1", "X2", "Value")
sampling$Value <- apply(sampling[,1:2], 1, DiceKriging::branin)
# negative expected improvement function (we try to minimize)
Neg_EI = function(x) {
y <- predict(fitted_model, matrix(x,nrow = 1), "UK")$mean
s <- predict(fitted_model, matrix(x,nrow = 1), "UK")$sd
z = (f_min-y)/s
-(f_min-y)*pnorm(z)-s*dnorm(z)
}
plot(sampling$X1,sampling$X2,col="blue",pch=20)
abline(v=(1:20)/20)
abline(h=(1:20)/20)
plot(sampling$X1,sampling$X2,col="blue",pch=20)
abline(v=(0:20)/20)
abline(h=(0:20)/20)
source("C:/Users/bradl/Desktop/STATS 202C/Bradley Updates/Stats202c_profit (most recent).R")
View(data)
